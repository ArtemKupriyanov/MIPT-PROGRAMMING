{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from scipy import misc\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import colorsys\n",
    "import hog_upd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лог регрессия, моя старая реалиазация для deep bayes (она выдавалась почти готовой, там нужно было буквально пару строчек написать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World again from __main__!\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from scipy.optimize.linesearch import scalar_search_wolfe2\n",
    "\n",
    "# Используйте scipy.special для вычисления численно неустойчивых функций\n",
    "# https://docs.scipy.org/doc/scipy/reference/special.html#module-scipy.special\n",
    "\n",
    "\n",
    "class LineSearchTool(object):\n",
    "    \"\"\"\n",
    "    Line search tool for adaptively tuning the step size of the algorithm.\n",
    "    method : String containing 'Wolfe', 'Armijo' or 'Constant'\n",
    "        Method of tuning step-size.\n",
    "        Must be be one of the following strings:\n",
    "            - 'Wolfe' -- enforce strong Wolfe conditions;\n",
    "            - 'Armijo\" -- adaptive Armijo rule;\n",
    "            - 'Constant' -- constant step size.\n",
    "    kwargs :\n",
    "        Additional parameters of line_search method:\n",
    "        If method == 'Wolfe':\n",
    "            c1, c2 : Constants for strong Wolfe conditions\n",
    "            alpha_0 : Starting point for the backtracking procedure\n",
    "                to be used in Armijo method in case of failure of Wolfe method.\n",
    "        If method == 'Armijo':\n",
    "            c1 : Constant for Armijo rule\n",
    "            alpha_0 : Starting point for the backtracking procedure.\n",
    "        If method == 'Constant':\n",
    "            c : The step size which is returned on every step.\n",
    "    \"\"\"\n",
    "    def __init__(self, method='Wolfe', **kwargs):\n",
    "        self._method = method\n",
    "        if self._method == 'Wolfe':\n",
    "            self.c1 = kwargs.get('c1', 1e-4)\n",
    "            self.c2 = kwargs.get('c2', 0.9)\n",
    "            self.alpha_0 = kwargs.get('alpha_0', 1.0)\n",
    "        elif self._method == 'Armijo':\n",
    "            self.c1 = kwargs.get('c1', 1e-4)\n",
    "            self.alpha_0 = kwargs.get('alpha_0', 1.0)\n",
    "        elif self._method == 'Constant':\n",
    "            self.c = kwargs.get('c', 1.0)\n",
    "        else:\n",
    "            raise ValueError('Unknown method {}'.format(method))\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, options):\n",
    "        if type(options) != dict:\n",
    "            raise TypeError('LineSearchTool initializer must be of type dict')\n",
    "        return cls(**options)\n",
    "\n",
    "    def to_dict(self):\n",
    "        return self.__dict__\n",
    "\n",
    "    def line_search(self, oracle, x_k, d_k, previous_alpha=None):\n",
    "        alpha = None\n",
    "        if self._method == 'Constant':\n",
    "            alpha = self.c\n",
    "        elif self._method == 'Wolfe':\n",
    "            found = scalar_search_wolfe2(lambda al: oracle.func(x_k + al * d_k),\n",
    "                                         lambda al: oracle.grad(x_k + al * d_k).T.dot(d_k),\n",
    "                                         phi0=oracle.func(x_k),\n",
    "                                         derphi0=oracle.grad(x_k).T.dot(d_k),\n",
    "                                         c1=self.c1,\n",
    "                                         c2=self.c2,\n",
    "                                         amax=previous_alpha if previous_alpha is not None else\n",
    "                                         self.alpha_0)\n",
    "            alpha = found[0]\n",
    "        if (self._method == 'Armijo') | (not alpha):\n",
    "            alpha = previous_alpha if previous_alpha is not None else self.alpha_0\n",
    "            phi_zero = oracle.func(x_k)\n",
    "            phi_der_zero = oracle.grad(x_k).T.dot(d_k)\n",
    "            while oracle.func(x_k + alpha * d_k) >= phi_zero + self.c1 * alpha * phi_der_zero:\n",
    "                alpha = alpha * 0.5\n",
    "        \"\"\"\n",
    "        Finds the step size alpha for a given starting point x_k\n",
    "        and for a given search direction d_k that satisfies necessary\n",
    "        conditions for phi(alpha) = oracle.func(x_k + alpha * d_k).\n",
    "        Parameters\n",
    "        ----------\n",
    "        oracle : BaseSmoothOracle-descendant object\n",
    "            Oracle with .func_directional() and .grad_directional() methods implemented for computing\n",
    "            function values and its directional derivatives.\n",
    "        x_k : np.array\n",
    "            Starting point\n",
    "        d_k : np.array\n",
    "            Search direction\n",
    "        previous_alpha : float or None\n",
    "            Starting point to use instead of self.alpha_0 to keep the progress from\n",
    "             previous steps. If None, self.alpha_0, is used as a starting point.\n",
    "        Returns\n",
    "        -------\n",
    "        alpha : float or None if failure\n",
    "            Chosen step size\n",
    "        \"\"\"\n",
    "        return alpha\n",
    "\n",
    "\n",
    "def get_line_search_tool(line_search_options=None):\n",
    "    if line_search_options:\n",
    "        if type(line_search_options) is LineSearchTool:\n",
    "            return line_search_options\n",
    "        else:\n",
    "            return LineSearchTool.from_dict(line_search_options)\n",
    "    else:\n",
    "        return LineSearchTool()\n",
    "\n",
    "\n",
    "def gradient_descent(oracle, x_0, tolerance=1e-5, max_iter=10000,\n",
    "                     line_search_options=None, trace=False, display=False, method=None):\n",
    "    \"\"\"\n",
    "    Gradien descent optimization method.\n",
    "    Parameters\n",
    "    ----------\n",
    "    oracle : BaseSmoothOracle-descendant object\n",
    "        Oracle with .func(), .grad() and .hess() methods implemented for computing\n",
    "        function value, its gradient and Hessian respectively.\n",
    "    x_0 : np.array\n",
    "        Starting point for optimization algorithm\n",
    "    tolerance : float\n",
    "        Epsilon value for stopping criterion.\n",
    "    max_iter : int\n",
    "        Maximum number of iterations.\n",
    "    line_search_options : dict, LineSearchTool or None\n",
    "        Dictionary with line search options. See LineSearchTool class for details.\n",
    "    trace : bool\n",
    "        If True, the progress information is appended into history dictionary during training.\n",
    "        Otherwise None is returned instead of history.\n",
    "    display : bool\n",
    "        If True, debug information is displayed during optimization.\n",
    "        Printing format and is up to a student and is not checked in any way.\n",
    "    Returns\n",
    "    -------\n",
    "    x_star : np.array\n",
    "        The point found by the optimization procedure\n",
    "    message : string\n",
    "        \"success\" or the description of error:\n",
    "            - 'iterations_exceeded': if after max_iter iterations of the method x_k still doesn't satisfy\n",
    "                the stopping criterion.\n",
    "            - 'computational_error': in case of getting Infinity or None value during the computations.\n",
    "    history : dictionary of lists or None\n",
    "        Dictionary containing the progress information or None if trace=False.\n",
    "        Dictionary has to be organized as follows:\n",
    "            - history['time'] : list of floats, containing time in seconds passed from the start of the method\n",
    "            - history['func'] : list of function values f(x_k) on every step of the algorithm\n",
    "            - history['grad_norm'] : list of values Euclidian norms ||g(x_k)|| of the gradient on every step of the algorithm\n",
    "            - history['x'] : list of np.arrays, containing the trajectory of the algorithm. ONLY STORE IF x.size <= 2\n",
    "    Example:\n",
    "    --------\n",
    "    >> oracle = QuadraticOracle(np.eye(5), np.arange(5))\n",
    "    >> x_opt, message, history = gradient_descent(oracle, np.zeros(5), line_search_options={'method': 'Armijo', 'c1': 1e-4})\n",
    "    >> print('Found optimal point: {}'.format(x_opt))\n",
    "       Found optimal point: [ 0.  1.  2.  3.  4.]\n",
    "    \"\"\"\n",
    "    history = defaultdict(list) if trace else None\n",
    "    start_time = time.time()\n",
    "\n",
    "    line_search_tool = get_line_search_tool(line_search_options)\n",
    "    x_k = np.copy(x_0)\n",
    "    alpha_k = None\n",
    "    converged = False\n",
    "\n",
    "    initial_grad_norm = np.linalg.norm(oracle.grad(x_k))\n",
    "    \n",
    "    if method == 'custom':\n",
    "        x_k = np.zeros_like(x_0) # Начальное значение параметров w\n",
    "        return x_k,  'success', 'not'\n",
    "\n",
    "    for k in range(max_iter + 1):\n",
    "        f_k = oracle.func(x_k)\n",
    "        if np.isinf(f_k):\n",
    "            return x_k, \"computational_error\", history\n",
    "        grad_f_k = oracle.grad(x_k)\n",
    "        grad_norm = np.linalg.norm(grad_f_k)\n",
    "        if display:\n",
    "            print(\"time: \", time.time() - start_time)\n",
    "            print(\"func: \", f_k)\n",
    "            print(\"grad_norm: \", grad_norm)\n",
    "            print(\"x_k: \", x_k)\n",
    "        if history is not None:\n",
    "            history['time'].append(time.time() - start_time)\n",
    "            history['func'].append(f_k)\n",
    "            history['grad_norm'].append(grad_norm)\n",
    "            if x_k.shape[0] < 3:\n",
    "                history['x'].append(x_k)\n",
    "        if grad_norm**2 <= tolerance * initial_grad_norm**2:\n",
    "            converged = True\n",
    "            break\n",
    "        if k == max_iter:\n",
    "            break\n",
    "        d_k = (-1 * grad_f_k)\n",
    "        alpha_k = line_search_tool.line_search(oracle, x_k, d_k, 2 * alpha_k if alpha_k is not None else None)\n",
    "        x_k = x_k + alpha_k * d_k\n",
    "#     if converged:\n",
    "    return x_k, 'success', history\n",
    "#     else:\n",
    "#         return x_k, 'iterations_exceeded', history\n",
    "\n",
    "\n",
    "def lossf(w, X, y, l1, l2):\n",
    "    lossf = np.ones(y.shape).dot(np.logaddexp(np.zeros(y.shape), -1 * y * X.dot(w))) + \\\n",
    "                                                                      l1 * np.linalg.norm(w, ord=1) + \\\n",
    "                                                                      l2 * w.dot(w)\n",
    "    return lossf\n",
    "\n",
    "\n",
    "def gradf(w, X, y, l1, l2):\n",
    "    gradient_cont_diff = -1.0 * X.T.dot(scipy.special.expit(-1 * y * X.dot(w)) * y) + 2 * l2 * w\n",
    "    gradf = (gradient_cont_diff + l1 * np.sign(w)) * (np.abs(w) > 0) + \\\n",
    "            (w == 0) * ((gradient_cont_diff < -l1) * (gradient_cont_diff + l1) +\n",
    "                        (gradient_cont_diff > l1) * (gradient_cont_diff - l1))\n",
    "    return gradf\n",
    "\n",
    "\n",
    "class LRL1Oracle:\n",
    "    def __init__(self, X, y, l1=1e-4, l2=1e-4):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "\n",
    "    def func(self, w):\n",
    "        return lossf(w, self.X, self.y, self.l1, self.l2)\n",
    "\n",
    "    def grad(self, w):\n",
    "        return gradf(w, self.X, self.y, self.l1, self.l2)\n",
    "\n",
    "\n",
    "class LR(object):\n",
    "    def __init__(self, lr=1, l1=1e-4, l2=1e-4, num_iter=1000, verbose=0):\n",
    "        \"\"\"\n",
    "        Создание класса для лог регрессии\n",
    "        :param lr: float, длина шага для оптимизатора\n",
    "        :param l1: float, l1 коэффициент регуляризатора\n",
    "        :param l2: float, l2 коэффициент регуляризатора\n",
    "        :param num_iter: int, число итераций оптимизатора\n",
    "        :param verbose: bool, ключик для вывода\n",
    "        \"\"\"\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        self.w = None\n",
    "        self.lr = lr\n",
    "        self.verbose = verbose\n",
    "        self.num_iter = num_iter\n",
    "\n",
    "    def fit(self, X, y, method_='Constant', grad_method=None):\n",
    "        \"\"\"\n",
    "        Обучение логистической регрессии.\n",
    "        Настраивает self.w коэффициенты модели.\n",
    "        Если self.verbose == True, то выводите значение\n",
    "        функции потерь на итерациях метода оптимизации.\n",
    "        :param X: numpy.array размера  (N, M), dtype = np.float\n",
    "        :param y: numpy.array размера  (N,), dtype = np.int\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "\n",
    "        oracle = LRL1Oracle(X, y, self.l1, self.l2)\n",
    "        n, d = X.shape\n",
    "        ls_tool = LineSearchTool(method=method_, c=self.lr)\n",
    "        self.w = np.zeros(X.shape[1])\n",
    "        res = gradient_descent(oracle, self.w, max_iter=self.num_iter,\n",
    "                               line_search_options=ls_tool,\n",
    "                               display=self.verbose, trace=True, tolerance=1e-5, method=grad_method)\n",
    "        \n",
    "#         w0, loss, info = optimize.fmin_l_bfgs_b(\n",
    "#                     func, w0, fprime=None,\n",
    "#                     args=(X, target, 1. / C, sample_weight),\n",
    "#                     iprint=(verbose > 0) - 1, pgtol=tol, maxiter=max_iter)\n",
    "        \n",
    "#         print('okee', res[2])\n",
    "        self.w = res[0]\n",
    "        if res[1] != \"success\":\n",
    "            raise Exception(\"fitting failed: \" + res[1])\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Предсказание вероятности принадлежности объекта к классу 1.\n",
    "        Возвращает np.array размера (N,) чисел в отрезке от 0 до 1.\n",
    "        :param X: numpy.array размера  (N, M), dtype = np.float\n",
    "        :return: numpy.array размера  (N,), dtype = np.float\n",
    "        \"\"\"\n",
    "        # Вычислите вероятности принадлежности каждого\n",
    "        # объекта из X к положительному классу, используйте\n",
    "        # эту функцию для реализации LR.predict\n",
    "        probs = scipy.special.expit(X.dot(self.w))\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказание класса для объекта.\n",
    "        Возвращает np.array размера (N,) элементов 1 или -1.\n",
    "        :param X: numpy.array размера  (N, M), dtype = np.float\n",
    "        :return:  numpy.array размера  (N,), dtype = np.int\n",
    "        \"\"\"\n",
    "        # Вычислите предсказания для каждого объекта из X\n",
    "        probs = self.predict_proba(X)\n",
    "        predicts = np.ones(X.shape[0]) * (probs >= 0.5) - np.ones(X.shape[0]) * (probs < 0.5)\n",
    "        return predicts\n",
    "    \n",
    "def _predict_proba_lr(X_t, w, intercept=0.52):\n",
    "    \"\"\"Probability estimation for OvR logistic regression.\n",
    "    Positive class probabilities are computed as\n",
    "    1. / (1. + np.exp(-self.decision_function(X)));\n",
    "    multiclass is handled by normalizing that over all classes.\n",
    "    \"\"\"\n",
    "    prob = X_t.dot(w) + intercept\n",
    "    prob *= -1\n",
    "    np.exp(prob, prob)\n",
    "    prob += 1\n",
    "    np.reciprocal(prob, prob)\n",
    "    return np.vstack([1 - prob, prob]).T\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    print(\"Hello World again from %s!\" % __name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color_hist(img):    #bins_range=(0, 256)\n",
    "    R = img[:,:,0].reshape(-1)\n",
    "    G = img[:,:,1].reshape(-1)\n",
    "    B = img[:,:,2].reshape(-1)\n",
    "    responce = []\n",
    "    for color in [R, G, B]:\n",
    "        for threshold in [170, 210, 240]:\n",
    "            responce.append(np.sum(color[color >= threshold]))\n",
    "        for threshold in [80, 45, 10]:\n",
    "            responce.append(np.sum(color[color <= threshold]))\n",
    "    return responce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stats_for_file(array_file, num_diff=3):\n",
    "    responce = []\n",
    "    array_file = np.array(array_file)\n",
    "    for i in range(num_diff):\n",
    "        if i == 0:\n",
    "            responce += [array_file.mean(), array_file.min(), array_file.max(), array_file.std()]\n",
    "        else:\n",
    "            diff = np.diff(array_file , n = i)\n",
    "            responce += [diff.mean(), diff.min(), diff.max(), diff.std()]\n",
    "    return responce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flip_vertical(img):\n",
    "    return img[:, ::-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6905/6905 [03:04<00:00, 37.47it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "train_path = []\n",
    "\n",
    "for img_path in tqdm(glob('./train/*.jpg')):\n",
    "    img_orig = misc.imread(img_path)\n",
    "    img_chromatic = misc.imread(img_path, mode='L')\n",
    "    for img, img_crom in [(img_orig, img_chromatic), \n",
    "                                    (flip_vertical(img_orig), img_chromatic[:, ::-1])]:\n",
    "        \n",
    "        hg = hog_upd.hog(misc.imresize(img_crom, (64, 64)), flatten=True)\n",
    "        hg_g = hog_upd.hog(misc.imresize(img[:, :, 1], (64, 64)), flatten=True)\n",
    "        hg_b = hog_upd.hog(misc.imresize(img[:, :, 2], (64, 64)), flatten=True)\n",
    "#         hg_r = hog_upd.hog(misc.imresize(img[:, :, 0], (64, 64)), flatten=True)\n",
    "        \n",
    "        hog = list(hg) + get_stats_for_file(hg, num_diff=2) + get_stats_for_file(hg_g, num_diff=3) + get_stats_for_file(hg_b, num_diff=3) + get_stats_for_file(hg_r, num_diff=3)\n",
    "        img_col_hist = color_hist(img)\n",
    "        img_col_hist += color_hist(img[:16, :, :])\n",
    "        img_col_hist += color_hist(img[-16:, :, :])\n",
    "        stats = get_stats_for_file(img[:, :, 2].reshape(-1))\n",
    "        stats += get_stats_for_file(img[:, :, 1].reshape(-1))\n",
    "#         stats += get_stats_for_file(img[:, :, 0].reshape(-1))             \n",
    "        \n",
    "        stats_half = []\n",
    "        for sl in [1, 4, 8, 16]:\n",
    "            for color in range(1, 3):\n",
    "                stats_half += get_stats_for_file(img[:sl, :, color].reshape(-1))\n",
    "                stats_half += get_stats_for_file(img[-sl:, :, color].reshape(-1))\n",
    "\n",
    "        \n",
    "        mean_row = list(np.mean(img[:, :, 2], axis=1))\n",
    "        mean_row += list(np.mean(img[:, :, 1], axis=1))\n",
    "        mean_row += list(np.mean(img[:, :, 0], axis=1))\n",
    "        std_row = list(np.std(img[:, :, 2], axis=1))\n",
    "        std_row += list(np.std(img[:, :, 1], axis=1))\n",
    "        std_row += list(np.std(img[:, :, 0], axis=1))\n",
    "        max_row = list(np.max(img[:, :, 2], axis=1))\n",
    "        max_row += list(np.max(img[:, :, 1], axis=1))\n",
    "        max_row += list(np.max(img[:, :, 0], axis=1))\n",
    "        min_row = list(np.min(img[:, :, 2], axis=1))\n",
    "        min_row += list(np.min(img[:, :, 1], axis=1))\n",
    "        min_row += list(np.min(img[:, :, 0], axis=1))\n",
    "        \n",
    "        mean_col = list(np.mean(img[:, :, 2], axis=0))\n",
    "        mean_col += list(np.mean(img[:, :, 1], axis=0))\n",
    "        mean_col += list(np.mean(img[:, :, 0], axis=0))\n",
    "        std_col = list(np.std(img[:, :, 2], axis=0))\n",
    "        std_col += list(np.std(img[:, :, 1], axis=0))\n",
    "        std_col += list(np.std(img[:, :, 0], axis=0))\n",
    "        max_col = list(np.max(img[:, :, 2], axis=0))\n",
    "        max_col += list(np.max(img[:, :, 1], axis=0))\n",
    "        max_col += list(np.max(img[:, :, 0], axis=0))\n",
    "        min_col = list(np.min(img[:, :, 2], axis=0))\n",
    "        min_col += list(np.min(img[:, :, 1], axis=0))\n",
    "        min_col += list(np.min(img[:, :, 0], axis=0))\n",
    "        \n",
    "        X.append(hog + img_col_hist + stats + stats_half + mean_row + std_row + max_row + min_row + mean_col + std_col + max_col + min_col)\n",
    "\n",
    "        name = os.path.basename(img_path).split('_')[0].strip()\n",
    "        class_ = 1 if name == 'indoor' else 0\n",
    "        y.append(class_)\n",
    "        train_path.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4499"
      ]
     },
     "execution_count": 849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "y_train = y[:5524 * 2]\n",
    "y_test = y[5524 * 2:]\n",
    "train_paths = train_path[:5524 * 2]\n",
    "val_paths = train_path[5524 * 2:]\n",
    "X_train = X[:5524 * 2, :]\n",
    "X_test = X[5524 * 2:, :]\n",
    "y_train[y_train == 0] = -1\n",
    "y_test[y_test == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.array(list(map(lambda st: st if st > 1e-15 else 1, np.std(X_train, axis=0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaler(X_last):\n",
    "    X_scaled = (X_last - mean) / std\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = scaler(X_train)\n",
    "X_test = scaler(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LR at 0x7f71ee097b90>"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_1 = LR(num_iter=300, lr=0.1)\n",
    "clf_1.fit(X_train, y_train, 'Wolfe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mse(y_pred, y_test):\n",
    "    return np.sqrt( np.mean((y_test - y_pred) ** 2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.209067248082\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_1.predict_proba(X_test)\n",
    "print(mse((y_pred[0::2] + y_pred[1::2]) / 2, y_test_01[0::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = _predict_proba_lr(X_test, clf_1.w)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.211387122524\n"
     ]
    }
   ],
   "source": [
    "print(mse((y_pred[0::2] + y_pred[1::2]) / 2, y_test_01[0::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2960/2960 [02:32<00:00, 19.32it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_kaggle = []\n",
    "labels = []\n",
    "for img_path in tqdm(glob('./test/*.jpg')):\n",
    "    img_orig = misc.imread(img_path)\n",
    "    img_chromatic = misc.imread(img_path, mode='L')\n",
    "    for img, img_crom in [(img_orig, img_chromatic), (flip_vertical(img_orig), img_chromatic[:, ::-1])]:\n",
    "        hg = hog_upd.hog(misc.imresize(img_crom, (64, 64)), flatten=True)\n",
    "        hg_g = hog_upd.hog(misc.imresize(img[:, :, 1], (64, 64)), flatten=True)\n",
    "        hg_b = hog_upd.hog(misc.imresize(img[:, :, 2], (64, 64)), flatten=True)\n",
    "#         hg_r = hog_upd.hog(misc.imresize(img[:, :, 0], (64, 64)), flatten=True)\n",
    "        \n",
    "        hog = list(hg) + get_stats_for_file(hg, num_diff=2) + get_stats_for_file(hg_g, num_diff=3) + get_stats_for_file(hg_b, num_diff=3) + get_stats_for_file(hg_r, num_diff=3)\n",
    "        img_col_hist = color_hist(img)\n",
    "        img_col_hist += color_hist(img[:16, :, :])\n",
    "        img_col_hist += color_hist(img[-16:, :, :])\n",
    "        stats = get_stats_for_file(img[:, :, 2].reshape(-1))\n",
    "        stats += get_stats_for_file(img[:, :, 1].reshape(-1))\n",
    "#         stats += get_stats_for_file(img[:, :, 0].reshape(-1))             \n",
    "        \n",
    "        stats_half = []\n",
    "        for sl in [1, 4, 8, 16]:\n",
    "            for color in range(1, 3):\n",
    "                stats_half += get_stats_for_file(img[:sl, :, color].reshape(-1))\n",
    "                stats_half += get_stats_for_file(img[-sl:, :, color].reshape(-1))\n",
    "\n",
    "        \n",
    "        mean_row = list(np.mean(img[:, :, 2], axis=1))\n",
    "        mean_row += list(np.mean(img[:, :, 1], axis=1))\n",
    "        mean_row += list(np.mean(img[:, :, 0], axis=1))\n",
    "        std_row = list(np.std(img[:, :, 2], axis=1))\n",
    "        std_row += list(np.std(img[:, :, 1], axis=1))\n",
    "        std_row += list(np.std(img[:, :, 0], axis=1))\n",
    "        max_row = list(np.max(img[:, :, 2], axis=1))\n",
    "        max_row += list(np.max(img[:, :, 1], axis=1))\n",
    "        max_row += list(np.max(img[:, :, 0], axis=1))\n",
    "        min_row = list(np.min(img[:, :, 2], axis=1))\n",
    "        min_row += list(np.min(img[:, :, 1], axis=1))\n",
    "        min_row += list(np.min(img[:, :, 0], axis=1))\n",
    "        \n",
    "        mean_col = list(np.mean(img[:, :, 2], axis=0))\n",
    "        mean_col += list(np.mean(img[:, :, 1], axis=0))\n",
    "        mean_col += list(np.mean(img[:, :, 0], axis=0))\n",
    "        std_col = list(np.std(img[:, :, 2], axis=0))\n",
    "        std_col += list(np.std(img[:, :, 1], axis=0))\n",
    "        std_col += list(np.std(img[:, :, 0], axis=0))\n",
    "        max_col = list(np.max(img[:, :, 2], axis=0))\n",
    "        max_col += list(np.max(img[:, :, 1], axis=0))\n",
    "        max_col += list(np.max(img[:, :, 0], axis=0))\n",
    "        min_col = list(np.min(img[:, :, 2], axis=0))\n",
    "        min_col += list(np.min(img[:, :, 1], axis=0))\n",
    "        min_col += list(np.min(img[:, :, 0], axis=0))\n",
    "#         X.append(hog + img_col_hist + list(misc.imresize(img_crom, (8, 8)).reshape(-1))  + stats + stats_half + mean_row + std_row + max_row + min_row +  mean_col + std_col + max_col + min_col)\n",
    "        X_test_kaggle.append(hog + img_col_hist + stats + stats_half + mean_row + std_row + max_row + min_row + mean_col + std_col + max_col + min_col)\n",
    "        \n",
    "        name = int(os.path.basename(img_path).split('_')[-1].split('.')[0])\n",
    "        labels.append(name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_kaggle = np.array(X_test_kaggle)\n",
    "X_test_kaggle_scaled = scaler(X_test_kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# не помню, как считал тут параметр, вроде одно из них, но скор и там, и там, хороший\n",
    "y_pred = clf_1.predict_proba(X_test_kaggle_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = _predict_proba_lr(X_test_kaggle_scaled, clf_1.w)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = (y_pred[::2] + y_pred[1::2])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = labels[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Засылаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer(y_pred, labels):\n",
    "    df = pd.concat([pd.DataFrame(labels), pd.DataFrame(y_pred)], axis=1)\n",
    "    df.columns = ['id', 'res']\n",
    "    df.index = df.id\n",
    "    df = df.drop('id', axis=1)\n",
    "    df.to_csv('hog_hist_visionhack_features_half.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_answer(y_pred, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
